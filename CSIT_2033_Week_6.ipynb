{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wjtopp3/CSIT-2033/blob/main/CSIT_2033_Week_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Science and AI\n",
        "- Data Science Topics\n",
        "- AI Topics\n"
      ],
      "metadata": {
        "id": "o_tuaK22v4nB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Science Topics\n",
        "\n",
        "1. Input Validation and Sanitization\n",
        "\n",
        "2. Memory Management and Resource Control\n",
        "\n",
        "3. Access Control and Data Privacy\n",
        "\n",
        "4. Secure Data Storage and Serialization\n",
        "\n",
        "5. Audit Logging and Error Handling\n",
        "\n",
        "6. Third-Party Library and Dependency Management"
      ],
      "metadata": {
        "id": "O_afjcKVh3DC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Input Validation and Sanitization\n",
        "- Ensure all data inputs (e.g., CSVs, JSON, user uploads) are validated before processing."
      ],
      "metadata": {
        "id": "GZb9t_h3mIva"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ› ï¸ Hands-On: Clean Data with Pandas Built-in Methods\n",
        "- Use Pandas' built-in methods to check for missing values, unexpected types, or malformed rows.\n"
      ],
      "metadata": {
        "id": "XX7iadKxQ9LH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pandas"
      ],
      "metadata": {
        "id": "jPvR1xaUaH3v",
        "outputId": "dd64672f-dde5-44db-dcd8-fad349114263",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# input data\n",
        "data = {\n",
        "    \"name\": [\"Alice\", \"Bob\", None],\n",
        "    \"age\": [25, \"unknown\", 30],\n",
        "    \"email\": [\"alice@example.com\", \"bob[at]example.com\", \"carol@example.com\"]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Check for missing values\n",
        "if df.isnull().values.any():\n",
        "    print(\"Warning: Missing values detected!\")\n",
        "    print(df.isnull().sum())\n",
        "\n",
        "# Check for unexpected types (e.g., non-numeric ages)\n",
        "if not pd.api.types.is_numeric_dtype(df['age']):\n",
        "    print(\"Warning: Non-numeric values detected in 'age' column!\")\n",
        "    print(df['age'])\n",
        "\n",
        "# Sanitize: Attempt to coerce 'age' to numeric, mark errors\n",
        "df['age'] = pd.to_numeric(df['age'], errors='coerce')\n",
        "\n",
        "# Check for malformed email addresses (basic check)\n",
        "invalid_emails = df[~df['email'].str.contains(r\"^[^@]+@[^@]+\\.[^@]+$\", regex=True)]\n",
        "if not invalid_emails.empty:\n",
        "    print(\"Warning: Malformed email addresses found!\")\n",
        "    print(invalid_emails['email'])\n",
        "\n",
        "print(\"\\nCleaned DataFrame:\")\n",
        "print(df)\n"
      ],
      "metadata": {
        "id": "Wkmj4P1hmA1J",
        "outputId": "b7e8103b-dc09-48ec-9eb4-ce0e9f2361dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Missing values detected!\n",
            "name     1\n",
            "age      0\n",
            "email    0\n",
            "dtype: int64\n",
            "Warning: Non-numeric values detected in 'age' column!\n",
            "0         25\n",
            "1    unknown\n",
            "2         30\n",
            "Name: age, dtype: object\n",
            "Warning: Malformed email addresses found!\n",
            "1    bob[at]example.com\n",
            "Name: email, dtype: object\n",
            "\n",
            "Cleaned DataFrame:\n",
            "    name   age               email\n",
            "0  Alice  25.0   alice@example.com\n",
            "1    Bob   NaN  bob[at]example.com\n",
            "2   None  30.0   carol@example.com\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prevent Malicious Payloads\n",
        "\n",
        "- A code injection pattern is a sequence of input (e.g. Excel formulas or SQL statements) intended to insert malicious code into a program, aiming to trick the system into executing unintended commands, altering behavior, or compromising security."
      ],
      "metadata": {
        "id": "YSOXB56OmvII"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ› ï¸ Hands-On: Sanitize Data\n",
        "- Use string prefix checks to sanitize potentially dangerous spreadsheet formulas in a DataFrame."
      ],
      "metadata": {
        "id": "fGWKaxQ7RM_H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# uploaded data\n",
        "data = {\n",
        "    \"username\": [\"alice\", \"bob\", \"=2+5\", \"+CMD|' /C calc'!A0\"],\n",
        "    \"comment\": [\"hello\", \"world\", \"=HYPERLINK('http://malicious.com')\", \"goodbye\"]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "print(\"Original data:\")\n",
        "print(df)\n",
        "\n",
        "# Sanitize dangerous formulas\n",
        "dangerous_prefixes = ('=', '+', '-', '@')\n",
        "\n",
        "def sanitize_formula(cell):\n",
        "    if isinstance(cell, str) and cell.startswith(dangerous_prefixes):\n",
        "        return \"'\" + cell\n",
        "    return cell\n",
        "\n",
        "# Apply sanitize_formula to each column separately\n",
        "df_sanitized = df.copy()\n",
        "for col in df_sanitized.columns:\n",
        "    # map() applies a function to each element in a column\n",
        "    df_sanitized[col] = df_sanitized[col].map(sanitize_formula)\n",
        "\n",
        "print(\"\\nSanitized data:\")\n",
        "print(df_sanitized)\n",
        "\n"
      ],
      "metadata": {
        "id": "xfTiWesZoLzK",
        "outputId": "bb4646fd-b34e-470d-afaf-c73ceb60ae0e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original data:\n",
            "             username                             comment\n",
            "0               alice                               hello\n",
            "1                 bob                               world\n",
            "2                =2+5  =HYPERLINK('http://malicious.com')\n",
            "3  +CMD|' /C calc'!A0                             goodbye\n",
            "\n",
            "Sanitized data:\n",
            "              username                              comment\n",
            "0                alice                                hello\n",
            "1                  bob                                world\n",
            "2                '=2+5  '=HYPERLINK('http://malicious.com')\n",
            "3  '+CMD|' /C calc'!A0                              goodbye\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sanitizing Data (cont)\n",
        "\n",
        "- We can **vectorize** the previous example which would run faster for larger data sets using the Pandas applymap method:\n",
        "\n",
        "```\n",
        "    mask = df.applymap(lambda x: isinstance(x, str) and\n",
        "                       x.startswith(dangerous_prefixes))\n",
        "```\n",
        "\n",
        "- This statement creates a boolean DataFrame (mask) where each cell is True if the original value is a string that starts with a dangerous prefix (such as =, +, -, or @), and False otherwise\n",
        "  - **~mask** inverts the boolean mask: True becomes False and vice versa.\n",
        "  - **\"'\" + df_sanitized** keeps the original values where the result is True, and replaces them with the sanitized value where it is False.\n",
        "\n",
        "- (ignore the deprecation warning)"
      ],
      "metadata": {
        "id": "hO7gvCUhps0L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# uploaded data\n",
        "data = {\n",
        "    \"username\": [\"alice\", \"bob\", \"=2+5\", \"+CMD|' /C calc'!A0\"],\n",
        "    \"comment\": [\"hello\", \"world\", \"=HYPERLINK('http://malicious.com')\", \"goodbye\"]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "print(\"Original data:\")\n",
        "print(df)\n",
        "\n",
        "# Dangerous prefixes\n",
        "dangerous_prefixes = ('=', '+', '-', '@')\n",
        "\n",
        "# Vectorized function to sanitize entire DataFrame\n",
        "# Create a boolean mask where cells need sanitization\n",
        "mask = df.map(lambda x: isinstance(x, str) and x.startswith(dangerous_prefixes))\n",
        "\n",
        "# Use np.where to efficiently sanitize\n",
        "df_sanitized = df.copy()\n",
        "df_sanitized = df_sanitized.where(~mask, \"'\" + df_sanitized)\n",
        "\n",
        "print(\"\\nSanitized data:\")\n",
        "print(df_sanitized)\n"
      ],
      "metadata": {
        "id": "5kWGRYHOpg_U",
        "outputId": "94ceb497-6040-4478-b755-e17217946a53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original data:\n",
            "             username                             comment\n",
            "0               alice                               hello\n",
            "1                 bob                               world\n",
            "2                =2+5  =HYPERLINK('http://malicious.com')\n",
            "3  +CMD|' /C calc'!A0                             goodbye\n",
            "\n",
            "Sanitized data:\n",
            "              username                              comment\n",
            "0                alice                                hello\n",
            "1                  bob                                world\n",
            "2                '=2+5  '=HYPERLINK('http://malicious.com')\n",
            "3  '+CMD|' /C calc'!A0                              goodbye\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ==== Complete Day 2 Exercise 1 Here ====\n",
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/FSCJ-FacultyDev/SWC-Columbus-2025/blob/main/exercises/Day2Exercise1_Sanitizing_Input.ipynb)\n"
      ],
      "metadata": {
        "id": "Zi_--XkgJEK9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Memory Management and Resource Control\n",
        "- Management and Resource Control is a critical aspect of secure data processing when working with large datasets or user-supplied input.\n",
        "- Loading entire files into memory at once can lead to excessive RAM usage, resulting in performance degradation or even crashing the application.\n",
        "- In security-sensitive environments, such behavior may be exploited by attackers to trigger denial-of-service (DoS) attacks through resource exhaustion.\n",
        "- A best practice is to use **chunked processing**, where data is read in manageable portions.\n",
        "- **pandas.read_csv(..., chunksize=10000)** allows iteration over large files without fully loading them into memory.\n",
        "### Memory Allocation\n",
        "- Be mindful of memory allocation in numerical computations.\n",
        "- Libraries like NumPy allow creation of very large arrays, which, if not properly constrained, can consume available memory or crash the interpreter. - Using array size limits, validating inputs, and preallocating memory only when necessary helps control memory footprint.\n",
        "- Monitoring tools like Python's [tracemalloc](https://docs.python.org/3/library/tracemalloc.html) or [psutil](https://github.com/giampaolo/psutil) can be integrated into a pipeline to track memory usage during runtime and enforce thresholds."
      ],
      "metadata": {
        "id": "3_wq_I3pSpgF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ› ï¸ Hands-On: Chunked CSV Reading with Memory Usage Monitoring"
      ],
      "metadata": {
        "id": "KLG7zEy2Ur-M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a large CSV file to test\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Create a large DataFrame with 10,000,000 rows\n",
        "num_rows = 10_000_000\n",
        "data = {\n",
        "    \"id\": range(num_rows),\n",
        "    \"value\": np.random.rand(num_rows),\n",
        "    \"category\": np.random.choice([\"A\", \"B\", \"C\", \"D\"], size=num_rows)\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Write to CSV\n",
        "df.to_csv(\"large_dataset.csv\", index=False)\n",
        "print(\"large_dataset.csv created successfully.\")"
      ],
      "metadata": {
        "id": "JPH5VkmcUKX-",
        "outputId": "eb3f0c26-43a3-4870-9143-8bd02cef1e4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "large_dataset.csv created successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Non-Chunked"
      ],
      "metadata": {
        "id": "8lwmSV84ZCqI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import psutil\n",
        "import os\n",
        "import time\n",
        "import gc\n",
        "\n",
        "print(\"NON-CHUNKED VERSION\")\n",
        "\n",
        "# create a Process object and monitor its memory and resource usage\n",
        "process = psutil.Process(os.getpid())\n",
        "\n",
        "start = time.time()\n",
        "df = pd.read_csv(\"large_dataset.csv\")\n",
        "avg = df[\"value\"].mean()\n",
        "end = time.time()\n",
        "\n",
        "mem_mb = process.memory_info().rss / (1024 ** 2)\n",
        "print(f\"Final average: {avg:.6f}\")\n",
        "print(f\"Final memory: {mem_mb:.2f} MB\")\n",
        "print(f\"Execution time: {end - start:.2f} seconds\")\n",
        "\n",
        "del df, avg\n",
        "gc.collect()\n",
        "\n"
      ],
      "metadata": {
        "id": "HkYlYCCYU-zT",
        "outputId": "e0f088ad-c644-4833-ee86-f1610b8ce7cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NON-CHUNKED VERSION\n",
            "Final average: 0.500028\n",
            "Final memory: 557.56 MB\n",
            "Execution time: 3.68 seconds\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chunked"
      ],
      "metadata": {
        "id": "e9na3btQZHmu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import psutil\n",
        "import os\n",
        "import gc\n",
        "import time\n",
        "\n",
        "print(\"CHUNKED VERSION (with accumulated average)\")\n",
        "\n",
        "process = psutil.Process(os.getpid())\n",
        "\n",
        "chunk_iter = pd.read_csv(\"large_dataset.csv\", chunksize=100000)\n",
        "\n",
        "# Initialize accumulator variables\n",
        "total_sum = 0.0\n",
        "total_count = 0\n",
        "\n",
        "start = time.time()\n",
        "for i, chunk in enumerate(chunk_iter):\n",
        "    chunk_sum = chunk[\"value\"].sum()\n",
        "    chunk_count = chunk[\"value\"].count()\n",
        "\n",
        "    total_sum += chunk_sum\n",
        "    total_count += chunk_count\n",
        "\n",
        "    del chunk, chunk_sum, chunk_count\n",
        "    gc.collect()\n",
        "\n",
        "end = time.time()\n",
        "\n",
        "# Compute the final mean\n",
        "final_avg = total_sum / total_count if total_count else 0\n",
        "\n",
        "mem_mb = process.memory_info().rss / (1024 ** 2)\n",
        "print(f\"Final average: {final_avg:.6f}\")\n",
        "print(f\"Final memory: {mem_mb:.2f} MB\")\n",
        "print(f\"Execution time: {end - start:.2f} seconds\")\n"
      ],
      "metadata": {
        "id": "lTsjnq_wUAX7",
        "outputId": "cd6215ee-c1ff-4695-a335-0c134f7a743d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CHUNKED VERSION (with accumulated average)\n",
            "Final average: 0.500028\n",
            "Final memory: 322.30 MB\n",
            "Execution time: 11.45 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chunking in a Nutshell\n",
        "- Non-chunked reading is faster but can consume significantly more memory.\n",
        "  - Risks crashes or DoS in memory-constrained environments.\n",
        "- Chunked reading uses less memory, making it safer for large or untrusted files.\n",
        "  - Introduces overhead due to repeated I/O and garbage collection.\n",
        "  - Can be optimized by increasing chunk size and minimizing per-chunk overhead."
      ],
      "metadata": {
        "id": "qkZ8Uy_hZYIr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Access Control and Data Privacy\n",
        "- Access control and data privacy come into play when  handling sensitive information, particularly in shared or multi-user environments.\n",
        "- One effective control strategy is to enforce access policies through **row and column filtering**, which ensures that users can only view or manipulate the data they are authorized to access (similar to creating a view in a database).\n",
        "- For example, an analyst might only be permitted to see records related to their assigned region (row-level filtering), or a customer support representative may be restricted from viewing personally identifiable information like social security numbers (column-level filtering)."
      ],
      "metadata": {
        "id": "VIFvSBiHgNoR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ› ï¸ Hands-On: Use Column Filtering"
      ],
      "metadata": {
        "id": "peRPeuDSg5rI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Sample data\n",
        "df = pd.DataFrame({\n",
        "    'name': ['Alice', 'Bob', 'Carol'],\n",
        "    'email': ['alice@example.com', 'bob@example.com', 'carol@example.com'],\n",
        "    'ssn': ['123-45-6789', '987-65-4321', '555-55-5555'],\n",
        "    'salary': [70000, 80000, 75000]\n",
        "})\n",
        "\n",
        "print(\"Original DataFrame:\")\n",
        "print(df)\n",
        "\n",
        "# Only allow non-sensitive columns to be accessed\n",
        "df_filtered = df[['name', 'email']]\n",
        "\n",
        "print(\"\\nFiltered DataFrame (restricted access):\")\n",
        "print(df_filtered)"
      ],
      "metadata": {
        "id": "siazyb6gguvA",
        "outputId": "7e54cd76-9b81-47df-c832-83c47325cd10",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original DataFrame:\n",
            "    name              email          ssn  salary\n",
            "0  Alice  alice@example.com  123-45-6789   70000\n",
            "1    Bob    bob@example.com  987-65-4321   80000\n",
            "2  Carol  carol@example.com  555-55-5555   75000\n",
            "\n",
            "Filtered DataFrame (restricted access):\n",
            "    name              email\n",
            "0  Alice  alice@example.com\n",
            "1    Bob    bob@example.com\n",
            "2  Carol  carol@example.com\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Anonymizing/Redacting Sensitive Fields\n",
        "- Anonymizing and redacting sensitive fields is a key data privacy technique used to protect personally identifiable information (PII) or confidential attributes within a dataset.\n",
        "- Anonymization typically involves transforming data so that individuals cannot be identified\n",
        "  - This can include name hashing or email address masking\n",
        "- Redaction replaces or removes sensitive values entirely (e.g., replacing a social security number with \"***-**-****\").\n",
        "- These methods are used when sharing data with third parties, performing analytics, or creating datasets for testing or training machine learning models."
      ],
      "metadata": {
        "id": "dxewUE5khAYb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ› ï¸ Hands-On: Anonymize Sensitive Data in a Pandas DataFrame\n",
        "- This program demonstrates how to anonymize sensitive fields in a DataFrame using pandas.\n",
        "- It starts with a sample dataset containing personally identifiable information (PII) such as names, email addresses, and Social Security numbers.\n",
        "- A copy of the original DataFrame is created, and the sensitive columns (name, email, and ssn) are overwritten with the placeholder value \"REDACTED\".\n",
        "- This simple anonymization hides sensitive information while preserving the overall structure and non-sensitive data (like salary) for further analysis or sharing."
      ],
      "metadata": {
        "id": "g1jpP0eBf-gj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Sample data\n",
        "df = pd.DataFrame({\n",
        "    'name': ['Alice', 'Bob', 'Carol'],\n",
        "    'email': ['alice@example.com', 'bob@example.com', 'carol@example.com'],\n",
        "    'ssn': ['123-45-6789', '987-65-4321', '555-55-5555'],\n",
        "    'salary': [70000, 80000, 75000]\n",
        "})\n",
        "\n",
        "print(\"Original DataFrame:\")\n",
        "print(df)\n",
        "\n",
        "# Anonymize sensitive fields\n",
        "df_anonymized = df.copy()\n",
        "df_anonymized['name'] = 'REDACTED'\n",
        "df_anonymized['email'] = 'REDACTED'\n",
        "df_anonymized['ssn'] = 'REDACTED'\n",
        "\n",
        "print(\"\\nAnonymized DataFrame:\")\n",
        "print(df_anonymized)"
      ],
      "metadata": {
        "id": "EZTx6R5agzhq",
        "outputId": "86208404-b408-4bbf-ff90-0192ba0de886",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original DataFrame:\n",
            "    name              email          ssn  salary\n",
            "0  Alice  alice@example.com  123-45-6789   70000\n",
            "1    Bob    bob@example.com  987-65-4321   80000\n",
            "2  Carol  carol@example.com  555-55-5555   75000\n",
            "\n",
            "Anonymized DataFrame:\n",
            "       name     email       ssn  salary\n",
            "0  REDACTED  REDACTED  REDACTED   70000\n",
            "1  REDACTED  REDACTED  REDACTED   80000\n",
            "2  REDACTED  REDACTED  REDACTED   75000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ› ï¸ Hands-On: Masking Sensitive Fields"
      ],
      "metadata": {
        "id": "m-qM_ISJhPTs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Sample data\n",
        "df = pd.DataFrame({\n",
        "    'name': ['Alice', 'Bob', 'Carol'],\n",
        "    'email': ['alice@example.com', 'bob@example.com', 'carol@example.com'],\n",
        "    'ssn': ['123-45-6789', '987-65-4321', '555-55-5555'],\n",
        "    'salary': [70000, 80000, 75000]\n",
        "})\n",
        "\n",
        "print(\"Original DataFrame:\")\n",
        "print(df)\n",
        "\n",
        "# Partially mask the SSN (show only last 4 digits)\n",
        "df_masked = df.copy()\n",
        "df_masked['ssn'] = df_masked['ssn'].apply(lambda x: \"***-**-\" + x[-4:])\n",
        "\n",
        "print(\"\\nPartially Masked DataFrame (SSN):\")\n",
        "print(df_masked)"
      ],
      "metadata": {
        "id": "dYCnWZuZhWrh",
        "outputId": "c5324104-e3e3-4c15-94af-fb7b3ec69e67",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original DataFrame:\n",
            "    name              email          ssn  salary\n",
            "0  Alice  alice@example.com  123-45-6789   70000\n",
            "1    Bob    bob@example.com  987-65-4321   80000\n",
            "2  Carol  carol@example.com  555-55-5555   75000\n",
            "\n",
            "Partially Masked DataFrame (SSN):\n",
            "    name              email          ssn  salary\n",
            "0  Alice  alice@example.com  ***-**-6789   70000\n",
            "1    Bob    bob@example.com  ***-**-4321   80000\n",
            "2  Carol  carol@example.com  ***-**-5555   75000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Secure Data Storage and Serialization\n",
        "- Choosing safe serialization methods and securing the storage are critical parts of building secure applications.\n",
        "- The two processes are closely related because:\n",
        "- Serialization is the process of converting data into a format (like JSON, pickle, XML) so it can be saved to storage or transmitted over a network.\n",
        "- Secure data storage requires protecting the data both at rest (stored persistently and not actively being transmitted or processed) and during serialization to prevent unauthorized access, tampering, or exploitation.\n",
        "- If serialization is handled insecurely, attackers can\n",
        "  - Inject malicious payloads.\n",
        "  - Read sensitive data from poorly protected files.\n",
        "  - Exploit insecure formats (like untrusted pickle files) to execute arbitrary code.\n",
        "\n"
      ],
      "metadata": {
        "id": "Jt5GOtJp2sHc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Avoid pickle\n",
        "- pickle can execute arbitrary code when deserializing.\n",
        "- Never load pickle files from untrusted sources.\n",
        "\n",
        "```\n",
        "# Pickle is unsafe\n",
        "import pickle\n",
        "\n",
        "# Dangerous: loading untrusted data\n",
        "with open('user_data.pkl', 'rb') as f:\n",
        "    data = pickle.load(f)  # Vulnerable to code execution\n",
        "```\n"
      ],
      "metadata": {
        "id": "_Wp_QpaW3yd1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Here**"
      ],
      "metadata": {
        "id": "APAGGdKeFqL6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# JSON Serializes Securely\n",
        "- **JavaScript Object Notation (JSON)**\n",
        "- JSON is data-only â€” it cannot embed executable code.\n",
        "- It is better suited for secure storage and exchange of structured data.\n",
        "- open standard data interchange format that uses human-readable text to store and transmit data objects consisting of nameâ€“value pairs and arrays (or other serializable values)\n",
        "- lightweight format usef for storing and transmitting data, often from a server to a web page\n",
        "- consists of **name/value pairings** -- similar to a Python dictionary structure\n",
        "\n",
        "```\n",
        "https://www.w3schools.com/whatis/whatis_json.asp\n",
        "\n",
        "# Examples of name/value pairings\n",
        "{\"firstName\":\"John\", \"lastName\":\"Doe\"}\n",
        "\n",
        "# Can have multiple value options\n",
        "{\n",
        "  \"username\": \"admin\",\n",
        "  \"password\": \"SuperSecret123!\",\n",
        "  \"permissions\": [\"read\", \"write\", \"delete\"]\n",
        "}\n",
        "\n",
        "# JSON Arrays\n",
        "\"employees\":[\n",
        "    {\"firstName\":\"John\", \"lastName\":\"Doe\"},\n",
        "    {\"firstName\":\"Anna\", \"lastName\":\"Smith\"},\n",
        "    {\"firstName\":\"Peter\", \"lastName\":\"Jones\"}\n",
        "]\n",
        "\n",
        "```\n",
        "\n",
        "```\n",
        "# Using JSON for serialization\n",
        "import json\n",
        "\n",
        "# Safe: loading trusted JSON data\n",
        "with open('user_data.json', 'r') as f:\n",
        "    data = json.load(f)  # Parses data only, no code execution\n",
        "```"
      ],
      "metadata": {
        "id": "QmkgdamW4AYC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# But JSON is Text - How Can It Be Secured?\n",
        "- Sensitive data can be encrypted before writing it to storage.\n",
        "- Always validate and sanitize data when loading from any serialized format.\n",
        "- NOTE: Fernet encryption, provided by the cryptography library, is a Python-specific symmetric encryption method that securely encrypts data using a shared secret key. It is popular due to its simplicity, but is not suitable for large file encryption or streaming since it requires that the entire message reside in memory.\n",
        "- We describe various cryptography libraries in the Day 3 content."
      ],
      "metadata": {
        "id": "y8p0fKaX4bCE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ› ï¸ Hands-On: Encrypt and Decrypt JSON Data\n",
        "- This program uses Fernet symmetric encryption to demonstrates secure encryption and decryption of JSON data.\n",
        "- It generates a key and saves it to a file, then creates a sample JSON object, serializes it to bytes, and encrypts it.\n",
        "- The encrypted data is then saved to a binary file.\n",
        "- The program then reads the key and encrypted data back from disk, validates that the encrypted file is not empty, and attempts to decrypt and parse the JSON securely.\n",
        "- If decryption fails due to tampering or corruption, it raises an InvalidToken error.\n",
        "- Finally, it prints the decrypted data and cleans up temporary files, ensuring confidentiality and integrity of the data at rest."
      ],
      "metadata": {
        "id": "eLaWecWjhOoL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from cryptography.fernet import Fernet, InvalidToken\n",
        "import json\n",
        "import os\n",
        "\n",
        "# generate and save the encryption key securely\n",
        "key = Fernet.generate_key()\n",
        "with open('secret.key', 'wb') as key_file:\n",
        "    key_file.write(key)\n",
        "\n",
        "# create a cipher using the key\n",
        "cipher = Fernet(key)\n",
        "\n",
        "# create JSON data to encrypt\n",
        "json_data = {\n",
        "    \"username\": \"admin\",\n",
        "    \"password\": \"SuperSecret123!\",\n",
        "    \"permissions\": [\"read\", \"write\", \"delete\"]\n",
        "}\n",
        "\n",
        "# serialize JSON to string and then encode to bytes\n",
        "json_string = json.dumps(json_data)\n",
        "data_bytes = json_string.encode('utf-8')\n",
        "\n",
        "# encrypt the serialized data\n",
        "encrypted_data = cipher.encrypt(data_bytes)\n",
        "\n",
        "# save the encrypted data to a file\n",
        "with open('secure_data.bin', 'wb') as data_file:\n",
        "    data_file.write(encrypted_data)\n",
        "\n",
        "# reload the key (yes, we already have it) and encrypt the data\n",
        "\n",
        "try:\n",
        "    # load the key\n",
        "    with open('secret.key', 'rb') as key_file:\n",
        "        loaded_key = key_file.read()\n",
        "\n",
        "    # recreate the cipher using the key\n",
        "    loaded_cipher = Fernet(loaded_key)\n",
        "\n",
        "    # load the encrypted data\n",
        "    with open('secure_data.bin', 'rb') as data_file:\n",
        "        encrypted_contents = data_file.read()\n",
        "\n",
        "    # validate - Check if the file is empty\n",
        "    if not encrypted_contents:\n",
        "        raise ValueError(\"Error: Encrypted file is empty.\")\n",
        "\n",
        "    # attempt decryption (sanitize - verify integrity)\n",
        "    decrypted_bytes = loaded_cipher.decrypt(encrypted_contents)\n",
        "\n",
        "    # decode bytes back to string and parse JSON\n",
        "    decrypted_json = json.loads(decrypted_bytes.decode('utf-8'))\n",
        "\n",
        "    # use the clean decrypted JSON data\n",
        "    print(\"Decrypted JSON data:\")\n",
        "    print(json.dumps(decrypted_json, indent=2))\n",
        "\n",
        "except InvalidToken:\n",
        "    print(\"Error: Decryption failed â€” data may have been tampered with!\")\n",
        "except Exception as e:\n",
        "    print(f\"Unexpected error: {e}\")\n",
        "\n",
        "# clean up files after demonstration\n",
        "os.remove('secure_data.bin')\n",
        "os.remove('secret.key')\n"
      ],
      "metadata": {
        "id": "eg0vFQ2P4ve2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Audit Logging and Error Handling\n",
        "## Audit Logging\n",
        "- Effective audit logging is a fundamental practice in secure software development.\n",
        "  - Audit logs serve as a record of significant system events, particularly those involving access to or modification of sensitive data. These logs are invaluable for identifying unauthorized behavior, debugging critical issues, and maintaining regulatory compliance.\n",
        "  - In Python, audit logging can be implemented using the built-in logging module or more advanced frameworks such as structlog or loguru (See Day 1), which support structured and context-rich output.\n",
        "- To ensure reliability, audit logs should be written to immutable, access-controlled storage with timestamps and user identifiers where applicable.\n",
        "  - A best practice is to use structured logging, which encodes log entries in a machine-readable format such as JSON.\n",
        "  - Structured logs make it easier to analyze large volumes of events using tools like [ELK Stack](https://www.elastic.co/elastic-stack) or [Splunk](https://www.splunk.com/).\n",
        "  - Rather than outputting raw strings, logs can include fields like event_type, user_id, timestamp, and operation_status.\n",
        "  - This avoids exposing sensitive application data or internal stack traces, which could otherwise be exploited if logs are improperly accessed.\n"
      ],
      "metadata": {
        "id": "7_24ipnnu2D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ› ï¸ Hands-On: Audit Logging using JSON"
      ],
      "metadata": {
        "id": "4n54o7h8iWML"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import json\n",
        "\n",
        "# set up the logger object\n",
        "logger = logging.getLogger(\"audit\")\n",
        "logger.setLevel(logging.INFO)\n",
        "handler = logging.FileHandler(\"audit.log\")\n",
        "formatter = logging.Formatter('%(message)s')\n",
        "handler.setFormatter(formatter)\n",
        "logger.addHandler(handler)\n",
        "\n",
        "# this function creates the JSON format of the entry\n",
        "def log_event(user_id, action, status):\n",
        "    log_entry = {\n",
        "        \"user_id\": user_id,\n",
        "        \"action\": action,\n",
        "        \"status\": status\n",
        "    }\n",
        "    logger.info(json.dumps(log_entry))\n",
        "\n",
        "#call the function with sample data\n",
        "log_event(\"user123\", \"data_export\", \"success\")\n"
      ],
      "metadata": {
        "id": "h3HxqeoOvKSE",
        "outputId": "bbbd6b56-18fb-4d85-ad62-0910f23e4ad3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:audit:{\"user_id\": \"user123\", \"action\": \"data_export\", \"status\": \"success\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Error Handling\n",
        "- Effective Error Handling is another fundamental practice of secure software development.\n",
        "  - Error handling should be implemented to catch exceptions without revealing system internals or sensitive data.\n",
        "  - When exceptions occur, error messages should be logged in a controlled and sanitized way, avoiding the exposure of stack traces or database query details.\n",
        "  - Instead of displaying raw exceptions to users or recording them verbatim in logs, the application should issue generic (but useful) messages and retain detailed logs for administrators only.\n"
      ],
      "metadata": {
        "id": "BswaJcFJvQRM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ› ï¸ Hands-On: Safe Error Handling Using JSON"
      ],
      "metadata": {
        "id": "kDyeyLENcXo3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import json\n",
        "\n",
        "# set up the logger object\n",
        "logger = logging.getLogger(\"audit\")\n",
        "logger.setLevel(logging.INFO)\n",
        "handler = logging.FileHandler(\"audit.log\")\n",
        "formatter = logging.Formatter('%(message)s')\n",
        "handler.setFormatter(formatter)\n",
        "logger.addHandler(handler)\n",
        "\n",
        "# a simple function to test error handling\n",
        "def divide(a, b):\n",
        "    try:\n",
        "        return a / b\n",
        "    except ZeroDivisionError:\n",
        "        logger.error(json.dumps({\n",
        "            \"error\": \"Attempted division by zero\",\n",
        "            \"operation\": \"divide\",\n",
        "            \"inputs\": {\"a\": a, \"b\": b}\n",
        "        }))\n",
        "        return \"Division by zero is not allowed.\"\n",
        "\n",
        "# function calls to test error handling\n",
        "print(divide(12, 2))\n",
        "print(divide(12, 0))"
      ],
      "metadata": {
        "id": "MPwpF-O6vVyj",
        "outputId": "2794ee92-d5fb-4da6-d253-5ad2b19ba16b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:audit:{\"error\": \"Attempted division by zero\", \"operation\": \"divide\", \"inputs\": {\"a\": 12, \"b\": 0}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6.0\n",
            "Division by zero is not allowed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### A NOTE about the output of these two function calls:\n",
        "```\n",
        "ERROR:audit:{\"error\": \"Attempted division by zero\", \"operation\": \"divide\", \"inputs\": {\"a\": 12, \"b\": 0}}\n",
        "The quotient is 6.0\n",
        "'Division by zero is not allowed.'\n",
        "```\n",
        "- The output may contain the **ERROR:audit:** message before the output of the print statement, even though the print function is called before the error occurs.\n",
        "- This is because the output from logger.error is sent to stderr and the output of the print statement on line 15 is sent to stdout.\n",
        "- Notebooks like Jupyter and Colab prioritize stderr and buffer stdout, so the ERROR message may appear before the output.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vQNWLizfLvpE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Integrating External Tools for Secure and Structured Logging\n",
        "- Consider integrating external tools or frameworks to enforce best practices.\n",
        "  - Libraries like [structlog](https://www.structlog.org/en/stable/) support event-based structured logging and context management\n",
        "  - Services like [Sentry](https://sentry.io/for/python) or [Datadog](https://www.datadoghq.com) provide real-time error monitoring and alerting.\n",
        "- Logging libraries should always be configured to mask or exclude sensitive fields (e.g., passwords, personal identifiers) before serialization.\n",
        "- Access to audit logs should be restricted to authorized personnel to prevent abuse.\n",
        "- Combining secure audit logging with structured logging and disciplined error handling provides greater resilience, maintainability, and compliance with standards such as HIPAA and GDPR."
      ],
      "metadata": {
        "id": "OqfQdasCvZD8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ==== Complete Day 2 Exercise 2 Here ====\n",
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/FSCJ-FacultyDev/SWC-Columbus-2025/blob/main/exercises/Day2Exercise2_StructuredLogging.ipynb)\n"
      ],
      "metadata": {
        "id": "C9VLkupFJkhn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Third-Party Library and Dependency Management"
      ],
      "metadata": {
        "id": "CggqPMEvIuEc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Third-Party Library and Dependency Management is a critical aspect of Python software development that ensures applications are built using reliable, secure, and maintainable external packages.\n",
        "  - Python's ecosystem boasts a vast array of third-party libraries available through the Python Package Index (PyPI), offering developers access to prebuilt functionality for tasks like web development, machine learning, data analysis, and cryptography.\n",
        "  - Relying on external packages introduces risks such as compatibility issues, deprecated APIs, or vulnerabilities.\n",
        "  - Proper dependency management practices help mitigate these risks and maintain the long-term health of a project.\n",
        "    - Keep dependencies up to date by patching known vulnerabilities.\n",
        "    - Use virtual environments or containers to isolate packages.\n",
        "    - Verify the integrity of libraries (e.g., via hash checks or using trusted sources like PyPI).\n",
        "- The most common tool for managing Python dependencies is pip, which allows developers to install packages using simple commands like *pip install requests*.\n",
        "- To ensure consistency across development environments, dependencies are often listed in a requirements.txt file. This file serves as a manifest of exact versions used in a project and can be regenerated using pip freeze > requirements.txt."
      ],
      "metadata": {
        "id": "V0pNC7QCln0X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the ! to run shell commands\n",
        "!pip install requests flask\n",
        "!pip freeze > requirements.txt"
      ],
      "metadata": {
        "id": "PRW1I3Flmc3b",
        "outputId": "4374702f-676c-47aa-ff5b-18d911f8d268",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.12/dist-packages (3.1.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.8.3)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.12/dist-packages (from flask) (8.2.1)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from flask) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from flask) (3.0.2)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from flask) (3.1.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "    - Example of a requirements.txt file:\n",
        "\n",
        "        flask==2.3.2  \n",
        "        requests==2.31.0  \n",
        "\n",
        "    - NOTE: The rest of the packages that are required by flask or requests either already exist or are downloaded and installed.\n",
        "\n"
      ],
      "metadata": {
        "id": "Qdso6vXkm1-8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Using virtual environments or containers like Docker ensures that dependencies are isolated, reproducible, and avoid polluting the global environment.\n",
        "  - Isolation enhances security by creating controlled, predictable environments and limiting exposure to global Python environments or system-wide packages.\n",
        "  - Reproducibility is especially important in teams or production deployments.\n",
        "  - Python developers frequently use tools like venv or virtualenv.\n",
        "  - These tools create project-specific environments where dependencies can be installed without conflicting with those of other projects.\n",
        "\n",
        "### The following is sample code only, it is not intended to be run in Colab -- use in Linux instead\n",
        "  \n",
        "```\n",
        "# Create a virtual environment using the venv command\n",
        "# (the following code is intended to run on Linux)\n",
        "# Name the virtual environment venv -- to make sure it's confusing for beginners\n",
        "python -m venv venv\n",
        "\n",
        "# Activate the virtual environment\n",
        "source venv/bin/activate  # On Windows: venv\\Scripts\\activate\n",
        "\n",
        "# Install the specific packages required from the requirements.txt file\n",
        "pip install -r requirements.txt\n",
        "\n",
        "# This is also a fun demo using the command prompt with Python installed\n",
        "```  "
      ],
      "metadata": {
        "id": "KO0h4TQXoUuV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- For larger projects or those requiring more sophisticated workflows, tools like Poetry or Pipenv offer enhanced dependency resolution, semantic versioning, and lock file generation.\n",
        "  - These tools help manage both direct and transitive dependencies more precisely.\n",
        "  - Integrating security tools such as pip-audit or GitHub's Dependabot helps identify known vulnerabilities in third-party packages, enabling proactive patching.\n",
        "- The following code uses pip-audit to audit your project's dependencies:"
      ],
      "metadata": {
        "id": "cSQGUe6cpZeI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pip-audit\n",
        "!pip-audit\n",
        "\n",
        "# This is another demo that is better using a command prompt on your machine\n",
        "# instead of using Colab"
      ],
      "metadata": {
        "id": "tg9aK-CRpoUa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "  - Keeping data science libraries like NumPy and Pandas up to date is crucial:\n",
        "    - patching security vulnerabilities\n",
        "    - improving performance\n",
        "    - ensuring compatibility with other modern libraries.\n",
        "  - Outdated packages can expose applications to known security issues that are publicly documented in CVEs (Common Vulnerabilities and Exposures).\n",
        "  - Tools like pip list --outdated, pip-review, or automated scanners such as GitHub Dependabot can help identify outdated packages.\n"
      ],
      "metadata": {
        "id": "_JbCUeWsW24d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use pip to check for outdated packages\n",
        "!pip list --outdated"
      ],
      "metadata": {
        "id": "Bj8W-HxHYEdv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "  - Running the above code block may reveal some 'outdated' packages\n",
        "  - Sometimes the latest is not always the greatest\n",
        "    - The newest version of a package may not be compatible with other stable packages being used."
      ],
      "metadata": {
        "id": "eZ_xhv6xYjZp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Verifying the integrity of libraries helps ensure a malicious or tampered package is not installed.\n",
        "  - Python supports hash checking mode via pip, which uses SHA256 hashes in requirements.txt to verify the exact files being installed."
      ],
      "metadata": {
        "id": "PXK6zWyTpBSX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip download numpy==2.2.5\n",
        "!pip hash /content/numpy-2.2.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl"
      ],
      "metadata": {
        "id": "I0qTaDiWdz-6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We can now add this information to our requirements.txt file:\n",
        "\n",
        "```\n",
        "numpy==2.2.5 \\\n",
        "  --hash=sha256:d84a1e9a5f2b4fadc3e9a2f8a69dfae9d048ba861b546f5e4f3a4a0b7a65c208\n",
        "```\n",
        "\n",
        "- Including a --hash with each dependency ensures the exact package file is used.\n",
        "- If someone uploads a malicious version of numpy==2.2.5 to PyPI, or if a mirror is compromised, pip will refuse to install it if the fileâ€™s SHA256 hash doesnâ€™t match.\n",
        "- This protects development and deployment pipelines from executing compromised code during automated builds or deployments."
      ],
      "metadata": {
        "id": "6v_6vRPuOB_C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Best Practices\n",
        "By following best practices in dependency management such as pinning versions, isolating environments, regularly auditing packages, and avoiding unmaintained libraries, developers can reduce technical debt and enhance the reliability and security of Python applications."
      ],
      "metadata": {
        "id": "Z5MQvyl2qTeV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NOTE from \"Alice and Bob Learn Secure Coding\":\n",
        "[2] Janca, Ch. 6\n",
        "\"You might have noticed that I suggested Pip Freeze and then said not to pin your libraries. How can you both freeze and keep updating libraries? Whenever you have a chance to do a code update, you want to update as many libraries as you can, to avoid technical debt. If you have the libraries pinned, they won't do that. But when you move from environment to environment (dev â€> QA â€> staging), you do not want versions of your code changing, as your testing will be inaccurate. Once you are ready to go beyond dev, you freeze, but before that, you update, update, update (especially libraries!).\""
      ],
      "metadata": {
        "id": "g3XmgZe1oAlA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AI Topics\n",
        "1. Using AI Safely and Securely\n",
        "2. Ethical Use of AI\n",
        "3. Data Integrity\n",
        "4. Defending Against Adversarial Attacks\n",
        "5. Secure Model Deployment and Monitoring"
      ],
      "metadata": {
        "id": "fmcfpMyRqIrg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Using Artificial Intelligence Safely and Securely\n",
        "\n",
        "- As artificial intelligence becomes increasingly integrated into software development workflows, developers must focus on safety and security.\n",
        "  - [**Safety**](https://arxiv.org/pdf/1606.06565) protects the system and its users from unintentional harm.\n",
        "  - This includes preventing software bugs, ensuring system reliability, avoiding accidents (e.g., crashing an autonomous system), and mitigating unintended consequences of AI behavior.\n",
        "  - Safety is about making sure the system does what it's supposed to do, and doesnâ€™t do something dangerous by mistake.\n",
        "  - [**Security**](https://arxiv.org/pdf/1802.07228) focuses on protecting the system from intentional harm, such as malicious attacks, unauthorized access, data breaches, or exploitation of vulnerabilities.\n",
        "  - It's about defending against external threats and ensuring confidentiality, integrity, and availability.\n",
        "- Tools such as code assistants, vulnerability scanners, and automated reasoning engines can help identify bugs, enforce secure coding standards, and streamline threat modeling.\n",
        "- Use caution when relying on AI-generated code, as it may introduce vulnerabilities or insecure results from training data."
      ],
      "metadata": {
        "id": "QN8lXnoViQ99"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Useful Tips from Alice and Bob\n",
        "[2] Ch. 15\n",
        "\n",
        "- Use AI to write user stories, documentation, and anything else that is written for your job.\n",
        "  - Doubleâ€check everything before showing it to anyone else; the first draft will likely be imperfect.\n",
        "- Use AI to help you write code; just make sure you check it first and don't give it sensitive data when asking for that help.\n",
        "- Use AI to help you find vulnerabilities; if you can share your code (e.g., open source), ask it to find vulnerabilities.\n",
        "  - It might not be as good as a SAST tool, but if you have an AI and you don't have a SAST tool, take what you can get.\n",
        "- Ask AI to do threat models for you; you will likely come up with lots of ridiculous ideas, but it usually has one or two good ones.\n",
        "- Ask AI for help with design, describe what you want, and see what it comes up with.\n",
        "  - This is like asking a junior employee: the ideas can be a bit wacky, but you get a lot of results really fast, and some of it is usable.\n",
        "- Ask AI to add comments to your code.\n",
        "  - It might be able to add more than you would have the patience for.\n",
        "  - Be sure they are kept concise and brief; no one wants to read a novel.\n",
        "- Ask AI to suggest bug fixes; some of them will be good."
      ],
      "metadata": {
        "id": "fxbx9IZOYjVI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Caveats:\n",
        "- Do not allow AI to make decisions on behalf of applications without oversight\n",
        "  - Each decision should have some other part of the code not controlled by the AI validate the decision\n",
        "  - AI should never be trusted to make an important decision on its own\n",
        "- An AI should not be able to control itself or others\n",
        "  - Many current researchers cannot fully explain how models work or why they hallucinate\n",
        "- Do not share sensitive or private information with an AI unless you own or control it\n",
        "- Always fully review AI-generated code\n",
        "  - Don't use it if you don't understand how it works\n",
        "  - [Junior developers sometimes rely too heavily on them without fully understanding the code being created](https://www.calcalistech.com/ctechnews/article/ybba8gx5n)\n",
        "  - [As a junior developer, itâ€™s important to learn the fundamentals](https://noncodersuccess.medium.com/should-junior-developers-use-ai-for-coding-24cc03717525)\n",
        "- Verify AI-generated content has not broken copyright\n",
        "  - Be sure it is original, properly attributed, and not derived from protected material."
      ],
      "metadata": {
        "id": "k1D_BSen9iMC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Ethical Use of AI\n",
        "## How Does AI Ethics Relate to Secure Development?\n",
        "1. Bias as a Security Risk\n",
        "\t- Biased models can lead to unfair treatment (e.g., in hiring or lending).\n",
        "\t- Security tie-in: Attackers can exploit known biases to game or manipulate models (e.g., feeding crafted inputs to skew recommendations).\n",
        "2. Data Privacy and Confidentiality\n",
        "\t- Users have a right to privacy; exposing sensitive data violates ethical standards.\n",
        "\t- Security tie-in: Poor privacy protections can lead to data leaks or model inversion attacks that reconstruct private training data.\n",
        "3. Accountability and Transparency\n",
        "\t- Users should know how decisions are made and be able to challenge them.\n",
        "\t- Security tie-in: Transparent systems allow for better auditing, threat detection, and accountability for model behavior and access.\n",
        "4. Adversarial Robustness as Ethical Responsibility\n",
        "\t- Systems should behave reliably and safely, especially in critical domains like healthcare or autonomous driving.\n",
        "\t- Security tie-in: Building defenses against adversarial attacks ensures models cannot be tricked into unsafe or harmful outputs.\n",
        "5. Fair Access and System Abuse\n",
        "\t- AI systems should not reinforce inequality or exclusion.\n",
        "\t- Security tie-in: Rate limiting, authentication, and abuse detection protect systems from being exploited for unfair advantage."
      ],
      "metadata": {
        "id": "vHHorBefrxTm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compliance with Legal and Regulatory Requirements\n",
        "- Compliance guidelines such as the General Data Protection Regulation (GDPR) and U.S. Equal Employment Opportunity Commission (EEOC) is essential.\n",
        "- These regulations mandate responsible data handling, privacy protections, and fairness in areas like automated decision-making, user profiling, and employment screening.\n",
        "- Developers must ensure that AI-driven applications are transparent, auditable, and designed to avoid bias or discrimination\n",
        "- Robust security is required to protect sensitive data.\n",
        "- Proper data validation, encryption, access control, and audit logging play a critical role."
      ],
      "metadata": {
        "id": "hzPGtdBsnV0R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "5. Secure Model Deployment\n",
        "- Restrict access to inference endpoints and model files.\n",
        "\t- Authenticate and authorize API requests to prevent abuse or reverse engineering.\n",
        "\t- Protect models in memory and at rest using encryption and secure containers.\n",
        "6. Privacy-Preserving Machine Learning\n",
        "- Implement techniques like differential privacy, federated learning, or homomorphic encryption.\n",
        "\t- Mask or anonymize sensitive features during preprocessing.\n",
        "\t- Ensure compliance with data minimization principles.\n",
        "7. Monitoring and Incident Response\n",
        "- Continuously monitor model behavior for drift, misuse, or attacks.\n",
        "\t- Set up logging and alerting systems for unexpected input/output patterns.\n",
        "\t- Have a rollback or patching process in place for compromised models."
      ],
      "metadata": {
        "id": "8WVl-ifdrOUI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Data Integrity\n",
        "\n",
        "- Maintaining data integrity is fundamental to the development of secure and reliable AI systems, beginning with validating and cleaning training data to detect anomalies, outliers, or potentially malicious inserts that could impact model behavior or introduce vulnerabilities.\n",
        "- In traditional software development, we only need to focus on testing and versioning code. [6] Ch. 1  \n",
        "- In machine learning, we have to test and version our data as well\n",
        "- Indiscriminately accepting all available data might hurt your modelâ€™s performance and even make it susceptible to data poisoning attacks\n",
        "- High-quality, trusted data input is essential to reduce the risk.\n",
        "- Basic strategies for regularly auditing models for signs of weak performance can help, as well as using advanced measures such as [defensive distillation](https://arxiv.org/pdf/1511.04508) and [feature squeezing](https://arxiv.org/pdf/1704.01155).\n",
        "- [Cisco: How to detect and mitigate AI data poisoning](https://outshift.cisco.com/blog/ai-data-poisoning-detect-mitigate)\n",
        "- Implementing data versioning and **provenance tracking** (keeping a record of data origin, changes, and history) allows developers to trace the origin, transformations, and usage of datasets over time.\n",
        "- MLOps frameworks like [DVC (Data Version Control)](https://dvc.org/doc) provide built-in support for versioning and provenance tracking.\n",
        "- Reproducibility, accountability, and rollback are essential to handle potential contamination or error.\n",
        "- Data validation libraries, logging pipelines, and checksum verification help enforce these safeguards."
      ],
      "metadata": {
        "id": "wQxEequQod-c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ› ï¸ Hands-On: Detect Model Poisoning Using IsolationForest\n",
        "- Detecting outliers using Scikit-Learn's IsolationForest algorithm can flag potentially poisoned samples during preprocessing.\n",
        "- IsolationForest detects outliers by repeatedly splitting data to see which points are easiest to isolate.\n",
        "- IsolationForest.fit_predict() labels each data point as either:\n",
        "  - 1 â†’ inlier (normal)\n",
        "  - -1 â†’ outlier (anomalous / possible poisoned sample)\n",
        "\n",
        "![IsolationForest](https://raw.githubusercontent.com/FSCJ-FacultyDev/SWC-Columbus-2025/main/images/day2-isolationforest.png)"
      ],
      "metadata": {
        "id": "5LWwJlpcrlkj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import IsolationForest\n",
        "\n",
        "# Simulate training data with potential poisoned samples\n",
        "np.random.seed(42)\n",
        "\n",
        "# Generate 100 data points with 2 features from a normal distribution\n",
        "#   ~68% within Â±1 standard deviation (i.e., between âˆ’1 and 1)\n",
        "#   ~95% within Â±2 standard deviations (i.e., between âˆ’2 and 2)\n",
        "#   ~99.7% within Â±3 standard deviations (i.e., between âˆ’3 and 3)\n",
        "normal_data = np.random.normal(loc=0.0, scale=1.0, size=(100, 2))\n",
        "\n",
        "# Manually create 2 outliers to simulate poisoned samples\n",
        "poisoned_data = np.array([[10, 10], [15, -12]])  # Simulated poisoned outliers\n",
        "\n",
        "# Stack the normal and poisoned data vertically to form one dataset\n",
        "data = np.vstack((normal_data, poisoned_data))\n",
        "\n",
        "# Convert to DataFrame for inspection\n",
        "df = pd.DataFrame(data, columns=[\"feature1\", \"feature2\"])\n",
        "\n",
        "# Apply Isolation Forest to detect outliers\n",
        "# (relative to this specific dataset)\n",
        "model = IsolationForest(contamination=0.05)\n",
        "df['anomaly'] = model.fit_predict(df[[\"feature1\", \"feature2\"]])\n",
        "\n",
        "# -1 indicates an outlier (possible poisoned sample)\n",
        "outliers = df[df['anomaly'] == -1]\n",
        "clean_data = df[df['anomaly'] == 1]\n",
        "\n",
        "print(\"Detected Outliers (Possible Poisoned Samples):\")\n",
        "print(outliers)"
      ],
      "metadata": {
        "id": "PJyNJuTUriaM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Here**"
      ],
      "metadata": {
        "id": "RdpwgMpUjF4K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Defending Against Adversarial Attacks\n",
        "- **Adversarial attacks** involve subtly modified inputs designed to fool machine learning models into making incorrect predictions.\n",
        "- These are often imperceptible to humans but can drastically alter model outputs, revealing vulnerabilities in both the model and the broader software systems that depend on its predictions.\n",
        "- **Adversarial training** is a widely adopted technique which involves augmenting the training dataset with adversarial examples so that the model learns to classify both normal and adversarial inputs correctly.\n",
        "  - This helps prepare the model for real-world attacks by simulating them during training.\n",
        "- **Input regularization techniques**, such as adding noise or using dropout, further harden models by discouraging overfitting and encouraging the model to generalize better, reducing its sensitivity to small variations.\n",
        "- Detection mechanisms can also be used at inference time to identify and reject potentially adversarial inputs.\n",
        "  - These might involve monitoring for abnormal activation patterns (i.e., inputs that trigger unexpected neuron activation responses) or statistical flags that suggest input manipulation.\n",
        "- Evaluating model robustness can be performed using specialized testing frameworks like [CleverHans](https://cleverhans.io/) and [Foolbox](https://foolbox.readthedocs.io/en/stable/#) which generate adversarial examples and assess model susceptibility.\n",
        "- These tools support continuous security testing practices similar to **fuzzing** (feeding a program  large volumes of unexpected or random data to discover  vulnerabilities, crashes, or unexpected behavior) and penetration testing in traditional software."
      ],
      "metadata": {
        "id": "n_6HMq8J8hUk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ› ï¸ Hands-On: Add Noise to Training Data"
      ],
      "metadata": {
        "id": "22PJiKG3ubfJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# adding noise for input regularization\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Original input (e.g., a vector representing an image or features)\n",
        "original_input = np.array([0.5, 0.7, 0.2, 0.9])\n",
        "\n",
        "# Add Gaussian noise with mean 0 and standard deviation 0.1\n",
        "noise = np.random.normal(loc=0.0, scale=0.1, size=original_input.shape)\n",
        "noisy_input = original_input + noise\n",
        "\n",
        "print(\"Original input:\", original_input)\n",
        "print(\"Noisy input:   \", noisy_input)"
      ],
      "metadata": {
        "id": "PruuEkJGEe5l",
        "outputId": "c58b46aa-a7b4-432e-ce84-d73c91bdb7ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original input: [0.5 0.7 0.2 0.9]\n",
            "Noisy input:    [0.47830993 0.51466876 0.23685273 1.06429103]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Deep learning example: apply Gaussian noise during training for robustness\n",
        "\n",
        "import numpy as np\n",
        "from tensorflow.keras.layers import Input, Dense, GaussianNoise\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Define the input layer with 4 features\n",
        "inputs = Input(shape=(4,))\n",
        "\n",
        "# Apply Gaussian noise (stddev = 0.1) to the input during training\n",
        "# Regularizes the model by making it less sensitive to small input changes\n",
        "x = GaussianNoise(0.1)(inputs)\n",
        "\n",
        "# Add a hidden dense layer with 16 neurons and ReLU activation\n",
        "x = Dense(16, activation='relu')(x)\n",
        "\n",
        "# Output layer with 1 neuron and sigmoid activation\n",
        "# (suitable for binary classification)\n",
        "outputs = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "# Build the model\n",
        "model = Model(inputs, outputs)\n",
        "\n",
        "# Compile the model with Adam optimizer and binary crossentropy loss function\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "# Sample batch of input data (3 samples with 4 features each)\n",
        "sample_input = np.array([\n",
        "    [0.5, 0.7, 0.2, 0.9],\n",
        "    [0.1, 0.3, 0.5, 0.2],\n",
        "    [0.9, 0.8, 0.1, 0.4]\n",
        "])\n",
        "\n",
        "# Perform a forward pass in training mode (noise is applied)\n",
        "predictions_with_noise = model(sample_input, training=True)\n",
        "\n",
        "# Perform a forward pass in inference mode (no noise applied)\n",
        "predictions_without_noise = model(sample_input, training=False)\n",
        "\n",
        "# Compare model predictions with and without input noise\n",
        "print(\"Predictions with noise:\\n\", predictions_with_noise.numpy())\n",
        "print(\"\\nPredictions without noise:\\n\", predictions_without_noise.numpy())"
      ],
      "metadata": {
        "id": "wGQtatJkFMlz",
        "outputId": "d72493d9-7276-4453-fd5b-6932a5d1ef08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions with noise:\n",
            " [[0.4574167 ]\n",
            " [0.49054003]\n",
            " [0.45604035]]\n",
            "\n",
            "Predictions without noise:\n",
            " [[0.44548067]\n",
            " [0.5020395 ]\n",
            " [0.44899598]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summary of results\n",
        "- The predictions with noise are close to but not exactly the same as those without noise.\n",
        "- The differences are generally small if the model is reasonably well-behaved and the standard deviation of the noise is low (0.1).\n",
        "- This difference illustrates the effect of input noise and how the model responds to slight variations in input values.\n",
        "- This technique helps in:\n",
        "  - Preventing overfitting by exposing the model to slightly altered data during training.\n",
        "  - Improving generalization to real-world data that may contain natural variability or noise.\n",
        "  - Making the model more robust against adversarial examples or unintended edge-case inputs.\n",
        "  - Enhancing resilience to input fuzzing and injection attacks, which is a valuable defensive measure."
      ],
      "metadata": {
        "id": "xFjUTrbiLAF_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Secure Model Deployment\n",
        "- Securely deploying machine learning models is critical in environments where privacy, intellectual property, or safety is at stake.\n",
        "- Unlike traditional software, machine learning models can be reverse-engineered or exploited in subtle ways, including model extraction attacks or unauthorized use of prediction APIs.\n",
        "- Deploying an AI model securely means more than serving it efficiently; it requires restricted access, hardened infrastructure, and strict interaction controls.\n",
        "- A decision must also be made of where computation will happen: in the cloud, on-premises, or at the edgeâ€”each with trade-offs in performance, privacy, and security.\n",
        "- One of the most effective strategies is to restrict access to inference endpoints and model files [8]  \n",
        "- In practice, this means hosting APIs behind a firewall, limiting network access with IP allowlists or VPNs, and storing model artifacts (like .pkl or .pt files) in protected locations with limited read access\n",
        "- For containerized deployments, models can be stored inside secure Docker images with reduced permissions, ensuring that even if a container is compromised, the model cannot be easily exfiltrated.\n",
        "- To prevent abuse, authentication and authorization mechanisms should be applied to every request, including API keys, OAuth tokens, or TLS certificates.\n",
        "- Rate limiting and anomaly detection can help identify and stop brute-force or scraping attempts, while request logging provides an audit trail to monitor access patterns.\n",
        "- Additionally, compiled model representations (e.g., [ONNX](https://docs.nvidia.com/deeplearning/tensorrt/latest/architecture/architecture-overview.html#onnx)) makes it harder for attackers to reverse-engineer model internals.\n",
        "  - ONNX, as an open standard, doesn't necessarily add much to the security, but additional actions can be taken such as obfuscating the model, disallowing direct access through APIs, encrypting it at rest, and using secure enclaves (see below).\n",
        "- Protecting models both in memory and at rest is essential to avoid leakage or tampering.\n",
        "- At rest, models should be encrypted using strong AES-based schemes, and stored in secure storage solutions like AWS KMS-integrated S3 buckets or encrypted volumes.\n",
        "- In memory, using secure enclaves (protected regions of memory) (e.g., [Intel SGX](https://www.intel.com/content/www/us/en/products/docs/accelerator-engines/software-guard-extensions.html)) can shield inference computations from the rest of the system.\n",
        "- Secure containers (e.g., an [AppArmor-enabled Docker image](https://docs.docker.com/engine/security/apparmor/)) and runtime sandboxes (like [gVisor](https://gvisor.dev/)) make sure a model operates within an isolated environment with limited system privileges."
      ],
      "metadata": {
        "id": "CitrAj9HHoco"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ› ï¸ Hands-On: Obfuscate a Model"
      ],
      "metadata": {
        "id": "1vzO53kJHqb6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision onnx onnxruntime onnxsim netron"
      ],
      "metadata": {
        "id": "ugv6q6hOD3Zt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a simple Pytorch model and export to ONNX\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import onnx\n",
        "\n",
        "# define a simple model\n",
        "class SimpleModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleModel, self).__init__()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(4, 8),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(8, 2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc(x)\n",
        "\n",
        "# instantiate and export to ONNX\n",
        "model = SimpleModel()\n",
        "dummy_input = torch.randn(1, 4)  # batch size 1, input size 4\n",
        "\n",
        "onnx_path = \"simple_model.onnx\"\n",
        "torch.onnx.export(model, dummy_input, onnx_path,\n",
        "                  input_names=[\"input\"], output_names=[\"output\"],\n",
        "                  opset_version=11)\n",
        "\n",
        "print(f\"Model exported to {onnx_path}\")\n"
      ],
      "metadata": {
        "id": "NTaLRHB2D4QX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the model from the ONNX data\n",
        "\n",
        "!pip install pydot graphviz\n",
        "\n",
        "import onnx\n",
        "from onnx.tools.net_drawer import GetPydotGraph, GetOpNodeProducer\n",
        "from IPython.display import Image, display\n",
        "\n",
        "model = onnx.load(onnx_path)\n",
        "pydot_graph = GetPydotGraph(model.graph, name=model.graph.name,\n",
        "                            rankdir=\"TB\",\n",
        "                            node_producer=GetOpNodeProducer(\"all\"))\n",
        "pydot_graph.write_png(\"onnx_model.png\")\n",
        "\n",
        "# Display the image\n",
        "display(Image(filename=\"onnx_model.png\"))\n"
      ],
      "metadata": {
        "id": "xwyKI0V4EBqo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import onnx\n",
        "\n",
        "# Load the ONNX model\n",
        "model = onnx.load(\"simple_model.onnx\")\n",
        "\n",
        "# obfuscate node names: hides layer-level semantics (e.g., 'fc1', 'relu')\n",
        "# by replacing them with generic identifiers\n",
        "for i, node in enumerate(model.graph.node):\n",
        "    node.name = f\"node_{i}\"\n",
        "    # Obfuscate input and output names per node: rename data flow tensors\n",
        "    # to mask data dependencies and internal structure\n",
        "    node.input[:] = [f\"in_{i}_{j}\" for j in range(len(node.input))]\n",
        "    node.output[:] = [f\"out_{i}_{j}\" for j in range(len(node.output))]\n",
        "\n",
        "# obfuscate graph-level input names: remove meaningful label names\n",
        "# from the modelâ€™s entry points\n",
        "for i, inp in enumerate(model.graph.input):\n",
        "    inp.name = f\"input_{i}\"\n",
        "\n",
        "# obfuscate output names: prevents revealing the target or\n",
        "# prediction type (e.g., \"output\", \"logits\", \"probabilities\")\n",
        "for i, out in enumerate(model.graph.output):\n",
        "    out.name = f\"output_{i}\"\n",
        "\n",
        "# obfuscate initializer names (e.g., weights and biases): masks learned\n",
        "# parameters so attackers cannot easily trace them to specific layers\n",
        "for i, init in enumerate(model.graph.initializer):\n",
        "    init.name = f\"param_{i}\"\n",
        "\n",
        "# save the obfuscated model\n",
        "onnx.save(model, \"simple_model_obfuscated.onnx\")\n",
        "print(\"obfuscated model saved as simple_model_obfuscated.onnx\")\n"
      ],
      "metadata": {
        "id": "-glMAUG_Jat-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the obfuscated model\n",
        "\n",
        "# layer and parameter names have been replaced with generic identifiers,\n",
        "# making the model less interpretable to humans and resistant to casual\n",
        "# casual inspection and basic reverse engineering.\n",
        "\n",
        "# does not protect model weights or prevent functional analysis.\n",
        "\n",
        "import onnx\n",
        "from onnx.tools.net_drawer import GetPydotGraph, GetOpNodeProducer\n",
        "from IPython.display import Image, display\n",
        "\n",
        "onnx_path = \"simple_model_obfuscated.onnx\"\n",
        "\n",
        "model = onnx.load(onnx_path)\n",
        "pydot_graph = GetPydotGraph(model.graph, name=model.graph.name,\n",
        "                            rankdir=\"TB\",\n",
        "                            node_producer=GetOpNodeProducer(\"all\"))\n",
        "pydot_graph.write_png(\"onnx_model.png\")\n",
        "\n",
        "# Display the image\n",
        "display(Image(filename=\"onnx_model.png\"))\n"
      ],
      "metadata": {
        "id": "ao6zFJLJJfN_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}